{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Q-BS1MJum3WHEIhmulXSyFoNdbDg2R8c?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwPfDFnz1ECg"
      },
      "source": [
        "# Machine Learning SP 2022/2023\n",
        "\n",
        "- Prof. Cesare Alippi\n",
        "- Giorgia Adorni ([`giorgia.adorni@usi.ch`](mailto:giorgia.adorni@usi.ch))<br>\n",
        "- Fatima Ezzeddine ([`fatima.ezzeddine@usi.ch`](mailto:fatima.ezzeddine@usi.ch))<br>\n",
        "- Alessandro Manenti ([`alessandro.manenti@usi.ch`](mailto:alessandro.manenti@usi.ch))\n",
        "\n",
        "---\n",
        "\n",
        "# Lab 03: Model Performance\n",
        "\n",
        "The objectives of the lab are as follows:\n",
        "\n",
        "- Evaluate the performance of a model\n",
        "- Perform splits on the data\n",
        "- Assess which model is the best along many models\n",
        "- Gain familiarity with the concept of models hyper-parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s8G3s6HzttP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMfbdgMUQvJX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Auxiliary code -------------------- #\n",
        "\n",
        "# function to plot decision boundaries\n",
        "def plot_decision_surface(model, x, y, transform=lambda x:x):\n",
        "    \n",
        "  from matplotlib.colors import ListedColormap\n",
        "  # color_maps\n",
        "  cm = plt.cm.RdBu\n",
        "  cols = ['#FF0000', '#0000FF']\n",
        "  cm_bright = ListedColormap(cols)  \n",
        "\n",
        "  #init figure\n",
        "  fig = plt.figure()\n",
        "\n",
        "  # Create mesh\n",
        "  h = .1  # step size in the mesh\n",
        "  x_min, x_max = x[:, 0].min() - .5, x[:, 0].max() + .5\n",
        "  y_min, y_max = x[:, 1].min() - .5, x[:, 1].max() + .5\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
        "                       np.arange(y_min, y_max, h))\n",
        "\n",
        "  # plot train data\n",
        "  cy = [cols[int(yi)] for yi in y]\n",
        "  plt.scatter(x[:, 0], x[:, 1], c=cy, cmap=cm_bright,\n",
        "              edgecolors='k')\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())\n",
        "\n",
        "  plt.xlabel(r'$x_1$')\n",
        "  plt.ylabel(r'$x_2$');\n",
        "\n",
        "  y_pred = model.predict(transform(np.c_[xx.ravel(), yy.ravel()]))\n",
        "\n",
        "  y_pred = y_pred.reshape(xx.shape)\n",
        "  plt.contourf(xx, yy, y_pred > 0.5, cmap=cm, alpha=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klMKmWT8KpcD"
      },
      "source": [
        "## Use-case scenario\n",
        "Consider the following use-case scenario: A company has approached us with a request to develop a machine learning model for one of their machines. We have been provided with a labeled dataset consisting of $(x_i, y_i)$ for $i=1, ..., N$. \n",
        "\n",
        "Our objective is to identify the best possible model, denoted as $f(x; \\hat \\theta)$, and provide an estimate of its performance, which is represented as $V(\\hat \\theta)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1fYESi8MXe4"
      },
      "outputs": [],
      "source": [
        "# Prepare some data\n",
        "N = 400\n",
        "\n",
        "np.random.seed(200402)\n",
        "# generating data points by samling from a random distribution and then changin the means of the distributions by adding constants to the values\n",
        "Xa = np.random.randn(N//4, 2)\n",
        "Xb = np.random.randn(N//4, 2) + np.array([ 8.,  1.])\n",
        "Xc = np.random.randn(N//4, 2) + np.array([-4., -1.])\n",
        "Xd = np.random.randn(N//4, 2) + np.array([ 4., -1.])\n",
        "\n",
        "#stacking the features together\n",
        "X = np.vstack([Xa, Xb, Xc, Xd])\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezNtzG5hzttQ"
      },
      "source": [
        "Creates two classes of equal size, one consisting of the first half of the elements in y (which are all zero) and the other consisting of the second half of the elements in y (which are all one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtEtGAdPMxRE"
      },
      "outputs": [],
      "source": [
        "# Assigning labels to our dataset\n",
        "\n",
        "# Creates a NumPy array y of size N with all elements initialized to zero.\n",
        "y = np.zeros((N,))\n",
        "\n",
        "# Sets the second half of the elements in y to one. \n",
        "y[N//2:] = 1\n",
        "\n",
        "# plot the data\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYyruTDKzttQ"
      },
      "outputs": [],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud6eXh23MVyF"
      },
      "source": [
        "## Train some models\n",
        "\n",
        "Let's start from a logistic regression ([sklearn doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)).\n",
        "\n",
        "\n",
        "We will try 2 types of models:\n",
        "- Logistic regression as the linear model\n",
        "- Feed Forward Neural Network as the non-linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKgpcppqNpoH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#initiate the class\n",
        "logreg = LogisticRegression()\n",
        "#feed it with X and y\n",
        "logreg.fit(X, y)\n",
        "#plot the decision surface\n",
        "plot_decision_surface(model=logreg, x=X, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weLS_eJHKpQ4"
      },
      "source": [
        "Let's try a feed-forward neural net ([keras doc](https://keras.io/models/sequential/)). \n",
        "\n",
        "We will use 3 keras component to build our FFNN\n",
        "- Sequential class\n",
        "- Dense class\n",
        "- Binary Cross Entropy \n",
        "\n",
        "Binary cross entropy is a common loss function used in machine learning, particularly for binary classification tasks where the goal is to predict one of two possible outcomes. It measures the difference between the predicted probabilities and the actual binary labels of a given dataset.\n",
        "\n",
        "When training neural networks for binary classification, we take the loss to be the __cross-entropy error function__: \n",
        "\n",
        "$$\n",
        "L({\\boldsymbol \\theta}) =  -\\frac1n \\sum_{i=1}^n \\bigg[y_i  \\log \\hat y_i + (1 - y_i)  \\log (1 - \\hat y_i)\\bigg]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI31Ut3nQb5I"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "def create_ffnn(neurons=3, activation=\"tanh\"):\n",
        "    # sequential class\n",
        "    model = Sequential()\n",
        "    # Dense class\n",
        "    model.add(Dense(neurons, input_shape=(2,), activation=activation))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # binary cross entropy    \n",
        "    model.compile(loss=BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "epochs = 300\n",
        "\n",
        "ffnn = create_ffnn()\n",
        "ffnn.fit(X, y, epochs=epochs, verbose=0)\n",
        "\n",
        "plot_decision_surface(model=ffnn, x=X, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myKkNJY6AMrM"
      },
      "source": [
        "## Performance assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAUs0grQS-cx"
      },
      "outputs": [],
      "source": [
        "# Set sizes\n",
        "n = int(N * .8)  # Training points, 80%\n",
        "l = N - n        # Test points, the resting 20%\n",
        "print(\"num training points: n=\",  n)\n",
        "print(\"num test points:     l= \", l)\n",
        "\n",
        "# Data split\n",
        "X_train, y_train = X[:n], y[:n]\n",
        "X_test, y_test = X[n:], y[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eprfe6CUAJR"
      },
      "outputs": [],
      "source": [
        "# Train the two models\n",
        "#logistic\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#nn\n",
        "ffnn = create_ffnn() \n",
        "ffnn.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "\n",
        "# Accuracy: rate of correct classifications:\n",
        "#logistic\n",
        "correct_classif = (logreg.predict(X_test) == y_test).astype(int)\n",
        "print(\"LR acc   :\", np.mean(correct_classif))\n",
        "#nn\n",
        "y_pred = np.array(ffnn.predict(X_test) > .5, dtype=int)[:, 0]\n",
        "correct_classif = (y_pred == y_test).astype(int)\n",
        "print(\"NN acc   :\", np.mean(correct_classif))\n",
        "\n",
        "# Plot boundaries\n",
        "plot_decision_surface(model=logreg, x=X_test, y=y_test)\n",
        "plot_decision_surface(model=ffnn,   x=X_test, y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw7Qh0rRRPgA"
      },
      "source": [
        "#### What's wrong?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTVjSPx0zttR"
      },
      "source": [
        "Let's Look at the confusion matrix.\n",
        "\n",
        "A confusion matrix is a table that summarizes the performance of a classification model by comparing the predicted labels with the actual labels. The confusion matrix shows the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) for each class.\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20221031145731/ConfusionMatrix2.png\" width=\"40%\">\n",
        "</div>\n",
        "\n",
        "\n",
        "1. True Negative – Indicates how many negative values are predicted as negative only by the model\n",
        "2. False Positive – Indicates how many negative values are predicted as positive values by the model\n",
        "3. False Negative – Indicates how many positive values are predicted as negative values by the model\n",
        "4. True Positive – Indicates how many positive values are predicted as positive only by the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3zWLEMRzttR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# the NN Confusion matrix\n",
        "print(f'accuracy score: {accuracy_score(y_test, y_pred)}')\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY0HGwt_RMA6"
      },
      "outputs": [],
      "source": [
        "# Plot split data\n",
        "plt.subplot(121)\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train);\n",
        "plt.subplot(122)\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIYgf6cZeWEo"
      },
      "source": [
        "We did not shuffled the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbgcu11LehCi"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data!\n",
        "# take some random permutations of N -> randomly permute betweeen 0 and N\n",
        "p = np.random.permutation(N)\n",
        "idx_train = p[:n]\n",
        "idx_test = p[n:]\n",
        "\n",
        "# Data split\n",
        "X_train, y_train = X[idx_train], y[idx_train]\n",
        "X_test, y_test = X[idx_test], y[idx_test]\n",
        "\n",
        "# Plot split data\n",
        "plt.subplot(121)\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train);\n",
        "plt.subplot(122)\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zuleJgtVYrk"
      },
      "source": [
        "\n",
        "SkLearn provides many [utilities](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection). For example, `train_test_split`, `ShuffleSplit` and `StratifiedShuffleSplit`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3ljaUwnOQ1O"
      },
      "outputs": [],
      "source": [
        "# or with SkLearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "idx_train, idx_test = train_test_split(np.arange(N), test_size=0.2, shuffle=True)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# Data split\n",
        "X_train, y_train = X[idx_train], y[idx_train]\n",
        "X_test, y_test = X[idx_test], y[idx_test]\n",
        "\n",
        "# Plot split data\n",
        "plt.subplot(121)\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train);\n",
        "plt.subplot(122)\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtF6T3xGgukx"
      },
      "outputs": [],
      "source": [
        "# Train the two models\n",
        "#logistic\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#nn\n",
        "ffnn = create_ffnn(8) \n",
        "ffnn.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "y_pred = np.array(ffnn.predict(X_test) > .5, dtype=int)[:, 0]\n",
        "\n",
        "# Evaluate accuracy\n",
        "acc_lr = logreg.score(X_test, y_test)\n",
        "[loss_nn, acc_nn] = ffnn.evaluate(X_test, y_test)\n",
        "print(\"acc_lr\", acc_lr)\n",
        "print(\"acc_nn\", acc_nn)\n",
        "\n",
        "# Plot boundaries\n",
        "plot_decision_surface(model=logreg, x=X_test, y=y_test)\n",
        "plot_decision_surface(model=ffnn, x=X_test, y=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF5r7TVpzttS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(f'accuracy score: {accuracy_score(y_test, y_pred)}')\n",
        "cf_mat = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix')\n",
        "print(cf_mat)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96tSPRKszttS"
      },
      "source": [
        "ROC (Receiver Operating Characteristic) curve is a graphical representation of the performance of a binary classification model.\n",
        "\n",
        "The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various classification thresholds.\n",
        "\n",
        "The area under the ROC curve (AUC) is a scalar value that represents the performance of the binary classification model. \n",
        "AUC ranges between 0 and 1, where 0 represents a model that makes all predictions wrong, and 1 represents a perfect model that makes all predictions correctly.\n",
        "\n",
        "Interpretation of the ROC curve and AUC:\n",
        "\n",
        "- The closer the ROC curve is to the upper-left corner of the plot, the better the performance of the binary classification model.\n",
        "- If the ROC curve is a diagonal line, it means that the model performs no better than random chance.\n",
        "- An AUC of 0.5 indicates that the model performs no better than random chance, while an AUC of 1 indicates perfect classification.\n",
        "\n",
        "AUC can be interpreted as the probability that the model will correctly classify a randomly chosen positive instance higher than a randomly chosen negative instance.\n",
        "\n",
        "In summary, the ROC curve and AUC are useful tools for evaluating the performance of binary classification models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIkVkgY3zttS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "def plot_roc_curve(true_y, y_prob, name):\n",
        "    \"\"\"\n",
        "    plots the roc curve based of the probabilities\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
        "    plt.plot(fpr, tpr, label=name)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "plot_roc_curve(y_test, ffnn.predict(X_test), 'FFNN')\n",
        "print(f'FFNN AUC score: {roc_auc_score(y_test, ffnn.predict(X_test) )}')\n",
        "\n",
        "\n",
        "plot_roc_curve(y_test, logreg.predict(X_test), 'Logistic Regression')\n",
        "print(f'FFNN AUC score: {roc_auc_score(y_test, logreg.predict_proba(X_test)[::,1] )}')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr3mqNKX2y8B"
      },
      "source": [
        "## Can we say which model is the best?\n",
        "\n",
        "What is a T-test?\n",
        "\n",
        "The null hypothesis of a T-test is a statement that there is no significant difference between the means of two groups.\n",
        "\n",
        "T-test is done by building the sample mean and the sample variance for the classification case.\n",
        "\n",
        "There are two types of T-tests: \n",
        "- unpaired samples T-test: used when the two groups being compared are independent of each other\n",
        "- paired samples T-test:  used when the two groups are dependent or related\n",
        "\n",
        "In our case we will be testing on the same test set, so we investigate the application of the paired T-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMK-joaW8CEU"
      },
      "source": [
        "\n",
        "$$\n",
        "e_i = \n",
        "\\begin{cases}\n",
        "1, & \\text{if } y_i =   f(x_i;\\hat \\theta)\\\\\n",
        "0, & \\text{if } y_i \\ne f(x_i;\\hat \\theta)\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "$$\\overline e = \\frac{1}{l}\\sum_{i=1}^l e_i ;\\qquad s^2 = \\overline e (1 - \\overline e)$$\n",
        "\n",
        "$$T = \\frac{\\overline e_{nn} - \\overline e_{lr}}\n",
        "           {\\sqrt{ \\frac{s^2_{nn}}{l} + \\frac{s^2_{lr}}{l}}}$$\n",
        "\n",
        "\n",
        "We want to see if we can fulfill the null hypothesis. We need to check if we are in a 95% confidence interval --> if the results of the statistics is inside the interval (-1.96, 1.96).           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtY5rl712zZR"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression part\n",
        "e_lr = (y_test == logreg.predict(X_test)).astype(int)\n",
        "mean_e_lr = e_lr.mean()\n",
        "s2_lr = mean_e_lr * (1 - mean_e_lr)\n",
        "print(\"mean: {} -- s2: {}\".format(mean_e_lr, s2_lr))\n",
        "\n",
        "# Neural Net part\n",
        "y_pred = (ffnn.predict(X_test) > .5)[:, 0].astype(int)\n",
        "e_nn = (y_test == y_pred).astype(int)\n",
        "mean_e_nn = e_nn.mean()\n",
        "s2_nn = mean_e_nn * (1 - mean_e_nn)\n",
        "print(\"mean: {} -- s2: {}\".format(mean_e_nn, s2_nn))\n",
        "\n",
        "# Test statistics\n",
        "T = (mean_e_nn - mean_e_lr) \n",
        "T /= np.sqrt( s2_nn / l + s2_lr / l )\n",
        "print(\"is T={} in 95\\% confidence interval (-1.96, 1.96) ?\".format(T))\n",
        "\n",
        "# t-test\n",
        "from scipy.stats import ttest_ind\n",
        "tt, p_val = ttest_ind(e_lr, e_nn, equal_var=False)\n",
        "print('t-test: T={:.2f}, p-value={:.4f}'.format(tt, p_val))\n",
        "\n",
        "# paired t-test\n",
        "from scipy.stats import ttest_rel\n",
        "tt, p_val = ttest_rel(e_lr, e_nn)\n",
        "print('t-test: T={:.2f}, p-value={:.4f}'.format(tt, p_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsXf0KBI5O5"
      },
      "source": [
        "## Did we finish?\n",
        "\n",
        "- The best model was the neural net,\n",
        "- We estimated its performance,\n",
        "- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b40Y9ecmYmhS"
      },
      "source": [
        "We retrain the best model on the entire dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL4xRLUDYsSo"
      },
      "outputs": [],
      "source": [
        "ffnn_final = create_ffnn()  # Remember: train the model from scratch.\n",
        "ffnn_final.fit(X, y, epochs=epochs, verbose=0)\n",
        "\n",
        "from keras.models import save_model \n",
        "save_model(ffnn_final, \"my_final_model.tf\")\n",
        "\n",
        "from keras.models import load_model \n",
        "loaded_model = load_model(\"my_final_model.tf\")\n",
        "\n",
        "# Check they are actually the same\n",
        "print(ffnn_final.evaluate(X, y))\n",
        "print(loaded_model.evaluate(X, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPTt0iNdS9xZ"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## K-fold cross-validation\n",
        "\n",
        "Say we have a single model and we want to identify a confidence interval for its accuracy.\n",
        "\n",
        "### Split the data: cross-validation\n",
        "\n",
        "Cross-validation is a technique used in machine learning to assess the performance of a model. In addition to making sure that we do not have bias in our dataset. It help us to be sure that whatever is been learnt on the training set it is gonna be generalized to the test set.\n",
        "\n",
        "It involves splitting the available data into training and validation sets, training the model on the training set, and then evaluating its performance on the validation set. This process is repeated several times with different splits of the data to obtain a more robust estimate of the model's performance.\n",
        "\n",
        "\n",
        "There are several types of cross-validation techniques, including:\n",
        "\n",
        "- k-fold cross-validation: This involves dividing the data into k equally sized folds, training the model k times, and using a different fold as the validation set each time.\n",
        "- Stratified cross-validation: This is used when the data is imbalanced, and ensures that the class distribution is preserved in the training and validation sets.\n",
        "\n",
        "The main idea behind cross-validation is that each observation in our dataset has the opportunity of being tested. In each round, we split the dataset into  k parts: one part is used for validation, and the remaining  k−1 parts are merged into a training subset for model evaluation. The figure below illustrates the process of 5-fold cross-validation:\n",
        "\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://www.mltut.com/wp-content/uploads/2020/05/cross-validation.png\" width=\"30%\">\n",
        "</div>\n",
        "\n",
        "$$ Fold:  k_i $$\n",
        "\n",
        "$$ Train:  D_{−k_i}$$\n",
        " \n",
        "$$ Evaluate: {x_i, y_i} \\in D_{k_i}$$\n",
        "\n",
        "$$Performance = \\frac{1}{N}  \\sum_{i=1}^N   {Performance_i} $$ \n",
        "\n",
        " \n",
        "where:\n",
        "\n",
        "$D_{-k_i}$ is the training set with the $i$-th fold removed\n",
        "\n",
        "$D_{k_i}$ is the validation set consisting of the $i$-th fold\n",
        "\n",
        "$\\text{Performance}_i$ is the performance metric (e.g. accuracy) on the $i$-th fold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01zmRGnlUA1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Utility to split the data\n",
        "kfcv = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "fold_iterator = kfcv.split(X, y)\n",
        "\n",
        "# Utility to split the data\n",
        "acc_nn = []\n",
        "\n",
        "for idx_train, idx_val in fold_iterator:\n",
        "\n",
        "    # split data\n",
        "    X_train, y_train = X[idx_train], y[idx_train]\n",
        "    X_val, y_val = X[idx_val], y[idx_val]\n",
        "\n",
        "    # train model\n",
        "    ffnn = create_ffnn(8)  # Remember: train the model from scratch.\n",
        "    ffnn.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "\n",
        "    # evaluate model\n",
        "    _, current_acc = ffnn.evaluate(X_val, y_val)\n",
        "    acc_nn.append(current_acc)\n",
        "\n",
        "print(\"Acc list:\", acc_nn)\n",
        "print(\"This is our estimated accuracy:  {:.3f} +- {:.3f}\".format(np.mean(acc_nn), np.std(acc_nn)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11TJvRzzttS"
      },
      "source": [
        "Here, we will have a set of ten models, but the question is which one to select?\n",
        "\n",
        "We have two additional alternatives:\n",
        "\n",
        "- Use all the data for training:\n",
        "    - build a new model M, this model will be a richer model in term of information, it will be better in in term of probability than the other models simply because we are considering more data.\n",
        "\n",
        "- Ensemble of models:\n",
        "    - We possess k models and we can employ all of them and establish a voting mechanism (A voting mechanism is a technique used in ensemble modeling where multiple models are combined to make a single prediction. Each model in the ensemble is allowed to make its own prediction based on the input data, and then a final prediction is made by taking a vote among the individual predictions.)\n",
        "    - Ensemble models are more resilient since they are less affected by individual data points, but the downside is the computational expense.  \n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://raw.githubusercontent.com/Project-MONAI/tutorials/9b796e43e527f29c6b8563b573513dff0fd86d98/figures/models_ensemble.png\" width=\"50%\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz4k0X72uVg1"
      },
      "source": [
        "Even from here we could have compared the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f4-k1e8xG3O"
      },
      "outputs": [],
      "source": [
        "# Utility to split the data\n",
        "kfcv = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "fold_iterator = kfcv.split(X, y)\n",
        "\n",
        "# Utility to split the data\n",
        "acc_nn = []\n",
        "acc_lr = []\n",
        "\n",
        "for idx_train, idx_val in fold_iterator:\n",
        "\n",
        "    X_train, y_train = X[idx_train], y[idx_train]\n",
        "    X_val, y_val = X[idx_val], y[idx_val]\n",
        "\n",
        "    ffnn = create_ffnn(8)  # Remember: train the model from scratch.\n",
        "    ffnn.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "\n",
        "    logreg = LogisticRegression() \n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    _, current_acc = ffnn.evaluate(X_val, y_val)\n",
        "    acc_nn.append(current_acc)\n",
        "    current_acc = logreg.score(X_val, y_val)\n",
        "    acc_lr.append(current_acc)\n",
        "\n",
        "print(\"LogReg list:   \", acc_lr)\n",
        "print(\"NeuralNet list:\", acc_nn)\n",
        "\n",
        "print(\"LogReg:     {:.3f} +- {:.3f}\".format(np.mean(acc_lr), np.std(acc_lr)))\n",
        "print(\"NeuralNet:  {:.3f} +- {:.3f}\".format(np.mean(acc_nn), np.std(acc_nn)))\n",
        "\n",
        "# Paired two sample test\n",
        "T, p_val = ttest_rel(acc_lr, acc_nn)\n",
        "print('t-test: T={:.2f}, p-value={:.4f}'.format(T, p_val))\n",
        "print(\"is T={:.2f} in 95\\% confidence interval (-1.96, 1.96) ?\".format(T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSeLHmXkM6Ih"
      },
      "source": [
        "## More than two models and hyper-parameter tuning\n",
        "\n",
        "In the context of neural networks, a parameter refers to a set of weights and biases that are learned during the training process. \n",
        "A hyperparameter, on the other hand, is a configuration variable that is set before the training process begins. These variables affect the behavior of the training algorithm itself, and can have a significant impact on the performance of the resulting model. \n",
        "\n",
        "Examples of hyperparameters include:\n",
        "    - learning rate\n",
        "    - the number of hidden layers\n",
        "    - the number of neurons in each layer\n",
        "    - the activation function used in each layer\n",
        "\n",
        "The performance of a neural network model heavily depends on the choice of hyperparameters: Hyperparameters can be adjusted in order to find the best combination for a given problem. This process is often referred to as hyperparameter tuning, and can be done using various techniques such as grid search, random search, etc..\n",
        "\n",
        "It can be a time-consuming process as it requires training multiple models with different hyperparameter configurations. However, it's a crucial step in building a successful machine learning model as it can significantly improve its performance and generalization ability.\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*5mStLTnIxsANpOHSwAFJhg.png\" width=\"40%\">\n",
        "</div>\n",
        "\n",
        "\n",
        "We will learn how to apply the grid search hyper-parameter tuning on the number of neurons and the activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdr8cuYxNbTz"
      },
      "outputs": [],
      "source": [
        "# neurons - activation\n",
        "model_parameters = [(3, \"tanh\"), \n",
        "                    (3, \"relu\"), \n",
        "                    (6, \"tanh\"), \n",
        "                    (6, \"relu\")]  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiBS8ryBzttT"
      },
      "source": [
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://studymachinelearning.com/wp-content/uploads/2019/10/summary_activation_fn.png\" width=\"50%\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFr9fuUZZiJL"
      },
      "source": [
        "### Data split\n",
        "\n",
        "The model is trained on the training set and evaluated on the testing set to assess its performance on unseen data.\n",
        "The validation set is used to tune hyperparameters such as the learning rate, and number of hidden units, etc.\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://b1739487.smushcdn.com/1739487/wp-content/uploads/2021/04/train-and-test-1-min-1.png?lossy=0&strip=1&webp=1\" width=\"35%\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exBdNL6WcmDX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
        "X_atr, X_val, y_atr, y_val = train_test_split(X_train, y_train, test_size=0.3, shuffle=True)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "# Model selection\n",
        "acc_list = []\n",
        "for (neurons, activation) in model_parameters:\n",
        "    print(\"Training NN with {} neurons and {} activation\".format(neurons, activation))\n",
        "\n",
        "    model = create_ffnn(neurons=neurons, activation=activation)\n",
        "    model.fit(X_atr, y_atr, epochs=epochs, verbose=0)\n",
        "\n",
        "    _, acc = model.evaluate(X_val, y_val)\n",
        "    acc_list.append(acc)\n",
        "\n",
        "imax = np.argmax(acc_list)\n",
        "print(\"Best model parameters:\", model_parameters[imax])\n",
        "\n",
        "# Performance of best model\n",
        "(neurons, activation) = model_parameters[imax]\n",
        "best_model = create_ffnn(neurons=neurons, activation=activation)\n",
        "best_model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "_, final_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Best model accuracy:\", final_acc)\n",
        "\n",
        "# Final trained model\n",
        "final_model = create_ffnn(neurons=neurons, activation=activation)\n",
        "final_model.fit(X, y, epochs=epochs, verbose=0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cctx7KHizttT"
      },
      "outputs": [],
      "source": [
        "model = create_ffnn(neurons=3, activation='tanh')\n",
        "model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
        "_, final_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"model accuracy:\", final_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}